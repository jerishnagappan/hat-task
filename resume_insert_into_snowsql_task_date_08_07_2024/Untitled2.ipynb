{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "120fead3-4037-46ed-a0fc-2dd1f799de58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created:\n",
      "           Name                     Email           Phone DOB  \\\n",
      "0  Rajesh Kumar  rajesh.kumar@example.com  +91 9876543210       \n",
      "\n",
      "                                          Experience Current Company  \\\n",
      "0  • Experienced in using industry-standard tools...                   \n",
      "\n",
      "                                 College  \\\n",
      "0  ABC College of Engineering, Bangalore   \n",
      "\n",
      "                                              Skills Generated Text  \\\n",
      "0  [• Proficient in test planning, test case desi...           None   \n",
      "\n",
      "   Total Words     Most Common Words  \n",
      "0          211  [(in, 10), (and, 8)]  \n",
      "Data inserted successfully into Snowflake\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import snowflake.connector  # Import Snowflake connector\n",
    "from snowflake.connector import DictCursor\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        pdf_text = ''\n",
    "        for page in pdf.pages:\n",
    "            pdf_text += page.extract_text()\n",
    "    return pdf_text\n",
    "\n",
    "# Function to parse resume content\n",
    "def parse_resume(ocr_text):\n",
    "    lines = ocr_text.split('\\n')\n",
    "    name = ''\n",
    "    email = ''\n",
    "    phone = ''\n",
    "    dob = ''\n",
    "    experience = ''\n",
    "    current_company = ''\n",
    "    college = ''\n",
    "    skills = []\n",
    "    in_skills_section = False\n",
    "    phone_pattern = r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]'\n",
    "    dob_pattern = r'\\d{1,2}-\\d{1,2}-\\d{4}'\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if not phone:\n",
    "            match = re.search(phone_pattern, line)\n",
    "            if match:\n",
    "                phone = match.group(0)\n",
    "\n",
    "        if not email:\n",
    "            email_match = re.search(email_pattern, line)\n",
    "            if email_match:\n",
    "                email = email_match.group(0)\n",
    "\n",
    "        if not dob and ('DOB' in line or 'Date of Birth' in line):\n",
    "            dob_match = re.search(dob_pattern, line)\n",
    "            if dob_match:\n",
    "                dob_value = dob_match.group(0)\n",
    "                try:\n",
    "                    dob = datetime.strptime(dob_value, '%d-%m-%Y').strftime('%Y-%m-%d')\n",
    "                except ValueError:\n",
    "                    dob = ''\n",
    "\n",
    "        if 'Experience' in line or 'Years of Experience' in line:\n",
    "            experience = line\n",
    "\n",
    "        if 'Current Company' in line or 'Company' in line:\n",
    "            current_company = line\n",
    "\n",
    "        if 'College' in line or 'University' in line:\n",
    "            college = line\n",
    "\n",
    "        if 'Skills' in line or 'Technical Skills' in line:\n",
    "            in_skills_section = True\n",
    "            continue\n",
    "\n",
    "        if line and not name:\n",
    "            name = line\n",
    "\n",
    "        if in_skills_section:\n",
    "            if line:\n",
    "                skills.append(line.strip())\n",
    "\n",
    "    return name, email, phone, dob, experience, current_company, college, skills\n",
    "\n",
    "\n",
    "def count_words(ocr_text):\n",
    "    words = ocr_text.split()\n",
    "    return len(words)\n",
    "\n",
    "\n",
    "def most_common_words(ocr_text, num_common=2):\n",
    "    words = re.findall(r'\\b\\w+\\b', ocr_text.lower())\n",
    "    common_words = Counter(words).most_common(num_common)\n",
    "    return common_words\n",
    "\n",
    "# Function to send request to Gemini API\n",
    "def send_request_to_gemini(prompt):\n",
    "    gemini_url = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=AIzaSyDdQoG3AzuDPkO1o-rxAGmLmQbpIOqo-As'\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(gemini_url, headers=headers, json=prompt)\n",
    "        if response.status_code == 200:\n",
    "            parsed_data = response.json()\n",
    "            if 'text' in parsed_data and parsed_data['text']:\n",
    "                generated_text = parsed_data['text']\n",
    "            else:\n",
    "                generated_text = None\n",
    "            return generated_text\n",
    "        else:\n",
    "            print(f\"Request failed with status code {response.status_code}\")\n",
    "            print(response.text)\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error with API request: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def insert_into_snowflake(df):\n",
    "    \n",
    "    conn_params = {\n",
    "        'account': 'akehzhr-rt23734',\n",
    "        'user': 'JERISH',\n",
    "        'password': 'Mahendrasingh@7',\n",
    "        'warehouse': 'COMPUTE_WH',\n",
    "        'database': 'EMPLOYEDB',\n",
    "        'schema': 'EMPLOYESCHEMA'\n",
    "    }\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        \n",
    "        conn = snowflake.connector.connect(\n",
    "            user=conn_params['user'],\n",
    "            password=conn_params['password'],\n",
    "            account=conn_params['account'],\n",
    "            warehouse=conn_params['warehouse'],\n",
    "            database=conn_params['database'],\n",
    "            schema=conn_params['schema']\n",
    "        )\n",
    "\n",
    "        cur = conn.cursor()\n",
    "\n",
    "       \n",
    "        for index, row in df.iterrows():\n",
    "            insert_query = \"\"\"\n",
    "                INSERT INTO resumes (name, email, phone, dob, college)\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            dob_value = row['DOB'] if row['DOB'] else None\n",
    "            cur.execute(insert_query, (\n",
    "                row['Name'],\n",
    "                row['Email'],\n",
    "                row['Phone'],\n",
    "                dob_value,\n",
    "                # row['Skills'],\n",
    "                row['College']\n",
    "            ))\n",
    "\n",
    "        conn.commit()\n",
    "        print(\"Data inserted successfully into Snowflake\")\n",
    "\n",
    "    except snowflake.connector.Error as e:\n",
    "        print(f\"Error inserting data into Snowflake: {e}\")\n",
    "\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    pdf_file_path = 'Resume.pdf'\n",
    "    ocr_text = extract_text_from_pdf(pdf_file_path)\n",
    "    name, email, phone, dob, experience, current_company, college, skills = parse_resume(ocr_text)\n",
    "    total_words = count_words(ocr_text)\n",
    "    common_words = most_common_words(ocr_text)\n",
    "\n",
    "    prompt = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [\n",
    "                    {\n",
    "                        \"text\": f\"Given the resume, fetch the name: {name}, email: {email}, phone: {phone}, dob: {dob}, experience: {experience}, current company: {current_company}, college: {college}, top 5 skills: {', '.join(skills)}, vertica as one of Full stack, Data Engineering, Dev Ops, Manual Testing, Automation.\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    prompt_json = json.dumps(prompt)\n",
    "    generated_text = send_request_to_gemini(prompt)\n",
    "    df = pd.DataFrame({\n",
    "        'Name': [name],\n",
    "        'Email': [email],\n",
    "        'Phone': [phone],\n",
    "        'DOB': [dob],\n",
    "        'Experience': [experience],\n",
    "        'Current Company': [current_company],\n",
    "        'College': [college],\n",
    "        'Skills': [skills],\n",
    "        'Generated Text': [generated_text],\n",
    "        'Total Words': [total_words],\n",
    "        'Most Common Words': [common_words]\n",
    "    })\n",
    "\n",
    "    print(\"DataFrame created:\")\n",
    "    print(df)\n",
    "\n",
    "    insert_into_snowflake(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9bbe970-085e-45e5-bd9b-023beab7cd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowflake-connector-python\n",
      "  Downloading snowflake_connector_python-3.11.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m643.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python)\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (1.16.0)\n",
      "Requirement already satisfied: cryptography<43.0.0,>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (41.0.4)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (23.2.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2023.3.post1)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.31.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2023.7.22)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (4.8.0)\n",
      "Collecting filelock<4,>=3.5 (from snowflake-connector-python)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sortedcontainers>=2.4.0 (from snowflake-connector-python)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.11.0)\n",
      "Collecting tomlkit (from snowflake-connector-python)\n",
      "  Downloading tomlkit-0.12.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0->snowflake-connector-python) (2.0.7)\n",
      "Downloading snowflake_connector_python-3.11.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading tomlkit-0.12.5-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: sortedcontainers, asn1crypto, tomlkit, filelock, snowflake-connector-python\n",
      "Successfully installed asn1crypto-1.5.1 filelock-3.15.4 snowflake-connector-python-3.11.0 sortedcontainers-2.4.0 tomlkit-0.12.5\n"
     ]
    }
   ],
   "source": [
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d72e465-4ae8-4a32-a290-3e877f3011cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
